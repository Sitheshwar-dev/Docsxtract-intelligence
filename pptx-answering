from fastapi import FastAPI, HTTPException, UploadFile, File
from pydantic import BaseModel
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import UnstructuredPowerPointLoader
import os
from dotenv import load_dotenv
import tempfile

load_dotenv()

# Initialize FastAPI app
app = FastAPI()

# Load OpenAI API key
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("OpenAI API key is missing!")

# Initialize Chroma vectorstore
persist_directory = "D:/GenAI/chroma_db"  # Path to store persistent Chroma data
embeddings = OpenAIEmbeddings()
vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings)

# Helper functions
def load_ppt_content(file_path: str) -> list:
    """Load content from a PowerPoint file."""
    loader = UnstructuredPowerPointLoader(file_path)
    documents = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=10)
    return text_splitter.split_documents(documents)

def store_embeddings(documents: list):
    """Store documents as embeddings in ChromaDB."""
    vectorstore.add_documents(documents)

def retrieve_relevant_data(question: str) -> list:
    """Retrieve relevant data from Chroma vectorstore."""
    retriever = vectorstore.as_retriever()
    results = retriever.get_relevant_documents(question)
    return [doc.page_content for doc in results]

def generate_answer(retrieved_data: list, question: str) -> str:
    """Generate an answer using the LLM."""
    context = "\n".join(retrieved_data)
    messages = [{"role": "user", "content": f"{context}\n\nQuestion: {question}"}]
    llm = ChatOpenAI(model="gpt-3.5-turbo")
    response = llm.invoke(messages)
    return response.content if hasattr(response, "content") else str(response)

# API Endpoints
@app.post("/upload_ppt/")
async def upload_ppt(file: UploadFile = File(...)):
    """Upload a PowerPoint file and store its content in ChromaDB."""
    try:
        # Save the uploaded file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pptx") as temp_file:
            temp_file.write(await file.read())
            temp_file_path = temp_file.name

        # Extract content and store embeddings
        documents = load_ppt_content(temp_file_path)
        store_embeddings(documents)
        return {"message": "PowerPoint content processed and stored successfully."}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        # Clean up temporary file
        os.remove(temp_file_path)

class QuestionRequest(BaseModel):
    question: str

@app.post("/ask/")
async def ask_question(request: QuestionRequest):
    """Ask a question based on the uploaded PowerPoint file."""
    try:
        # Retrieve relevant data and generate an answer
        relevant_data = retrieve_relevant_data(request.question)
        if not relevant_data:
            raise HTTPException(status_code=404, detail="No relevant data found.")
        answer = generate_answer(relevant_data, request.question)
        return {"answer": answer}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000)
